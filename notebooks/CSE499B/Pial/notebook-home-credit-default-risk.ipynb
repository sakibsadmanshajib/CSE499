{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, merge, Reshape, Dropout, Input, Flatten, Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "DATA_DIRECTORY = \"../input/home-credit-default-risk\"\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b823c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(DATA_DIRECTORY, 'application_train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIRECTORY, 'application_test.csv'))\n",
    "df = df_train.append(df_test)\n",
    "del df_train, df_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d83a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['AMT_INCOME_TOTAL'] < 20000000]\n",
    "df = df[df['CODE_GENDER'] != 'XNA']\n",
    "df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_group(days_birth):\n",
    "    age_years = -days_birth / 365\n",
    "    if age_years < 27: return 1\n",
    "    elif age_years < 40: return 2\n",
    "    elif age_years < 50: return 3\n",
    "    elif age_years < 65: return 4\n",
    "    elif age_years < 99: return 5\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b225ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
    "df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
    "df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)\n",
    "df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_group(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "df['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3\n",
    "np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
    "for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n",
    "    feature_name = 'EXT_SOURCES_{}'.format(function_name.upper())\n",
    "    df[feature_name] = eval('np.{}'.format(function_name))(\n",
    "        df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e03d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "df['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']    \n",
    "df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n",
    "df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f41dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mean(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00182beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_median(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f228bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_std(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1484c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sum(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbf93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\n",
    "df = do_median(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN')\n",
    "df = do_std(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_STD')\n",
    "df = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\n",
    "df = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\n",
    "df = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\n",
    "df = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\n",
    "df = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\n",
    "df = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\n",
    "df = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557135a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df, categorical_columns=None):\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    for col in categorical_columns:\n",
    "        df[col], uniques = pd.factorize(df[col])\n",
    "    return df, categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_application_columns(df):\n",
    "    drop_list = [\n",
    "        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n",
    "        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n",
    "        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
    "        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n",
    "        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n",
    "        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n",
    "        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n",
    "        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n",
    "        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n",
    "        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n",
    "        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n",
    "        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n",
    "        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n",
    "        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'\n",
    "    ]\n",
    "    for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n",
    "        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n",
    "    df.drop(drop_list, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b330dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, le_encoded_cols = label_encoder(df, None)\n",
    "df = drop_application_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1be339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36846372",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.read_csv(os.path.join(DATA_DIRECTORY, 'bureau.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25119e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n",
    "bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\n",
    "bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
    "bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12216645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    categorical_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n",
    "    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n",
    "                               for e in agg_df.columns.tolist()])\n",
    "    return agg_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13654356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n",
    "    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bureau_balance(path, num_rows= None):\n",
    "    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'))\n",
    "    bb, categorical_cols = one_hot_encoder(bb, nan_as_category= False)\n",
    "    # Calculate rate for each category with decay\n",
    "    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n",
    "    # Min, Max, Count and mean duration of payments (months)\n",
    "    agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n",
    "    bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')\n",
    "    del bb; gc.collect()\n",
    "    return bb_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category= False)\n",
    "bureau = bureau.merge(get_bureau_balance(DATA_DIRECTORY), how='left', on='SK_ID_BUREAU')\n",
    "bureau['STATUS_12345'] = 0\n",
    "for i in range(1,6):\n",
    "    bureau['STATUS_12345'] += bureau['STATUS_{}'.format(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da605dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM',\n",
    "    'AMT_CREDIT_SUM_DEBT', 'DEBT_PERCENTAGE', 'DEBT_CREDIT_DIFF', 'STATUS_0', 'STATUS_12345']\n",
    "agg_length = bureau.groupby('MONTHS_BALANCE_SIZE')[features].mean().reset_index()\n",
    "agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)\n",
    "bureau = bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')\n",
    "del agg_length; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUREAU_AGG = {\n",
    "    'SK_ID_BUREAU': ['nunique'],\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean', 'sum'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_1': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "    'STATUS_C': ['mean'],\n",
    "    'STATUS_X': ['mean'],\n",
    "    'CREDIT_ACTIVE_Active': ['mean'],\n",
    "    'CREDIT_ACTIVE_Closed': ['mean'],\n",
    "    'CREDIT_ACTIVE_Sold': ['mean'],\n",
    "    'CREDIT_TYPE_Consumer credit': ['mean'],\n",
    "    'CREDIT_TYPE_Credit card': ['mean'],\n",
    "    'CREDIT_TYPE_Car loan': ['mean'],\n",
    "    'CREDIT_TYPE_Mortgage': ['mean'],\n",
    "    'CREDIT_TYPE_Microloan': ['mean'],\n",
    "    'LL_AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'LL_DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'LL_STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_ACTIVE_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_UPDATE': ['min', 'mean'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "BUREAU_CLOSED_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'var'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'sum'],\n",
    "    'DAYS_CREDIT_UPDATE': ['max'],\n",
    "    'ENDDATE_DIF': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_LOAN_TYPE_AGG = {\n",
    "    'DAYS_CREDIT': ['mean', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'max'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "}\n",
    "\n",
    "BUREAU_TIME_AGG = {\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_bureau = group(bureau, 'BUREAU_', BUREAU_AGG)\n",
    "active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "agg_bureau = group_and_merge(active,agg_bureau,'BUREAU_ACTIVE_',BUREAU_ACTIVE_AGG)\n",
    "closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "agg_bureau = group_and_merge(closed,agg_bureau,'BUREAU_CLOSED_',BUREAU_CLOSED_AGG)\n",
    "del active, closed; gc.collect()\n",
    "for credit_type in ['Consumer credit', 'Credit card', 'Mortgage', 'Car loan', 'Microloan']:\n",
    "    type_df = bureau[bureau['CREDIT_TYPE_' + credit_type] == 1]\n",
    "    prefix = 'BUREAU_' + credit_type.split(' ')[0].upper() + '_'\n",
    "    agg_bureau = group_and_merge(type_df, agg_bureau, prefix, BUREAU_LOAN_TYPE_AGG)\n",
    "    del type_df; gc.collect()\n",
    "for time_frame in [6, 12]:\n",
    "    prefix = \"BUREAU_LAST{}M_\".format(time_frame)\n",
    "    time_frame_df = bureau[bureau['DAYS_CREDIT'] >= -30*time_frame]\n",
    "    agg_bureau = group_and_merge(time_frame_df, agg_bureau, prefix, BUREAU_TIME_AGG)\n",
    "    del time_frame_df; gc.collect()\n",
    "sort_bureau = bureau.sort_values(by=['DAYS_CREDIT'])\n",
    "gr = sort_bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].last().reset_index()\n",
    "gr.rename({'AMT_CREDIT_MAX_OVERDUE': 'BUREAU_LAST_LOAN_MAX_OVERDUE'}, inplace=True)\n",
    "agg_bureau = agg_bureau.merge(gr, on='SK_ID_CURR', how='left')\n",
    "agg_bureau['BUREAU_DEBT_OVER_CREDIT'] = \\\n",
    "    agg_bureau['BUREAU_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_AMT_CREDIT_SUM_SUM']\n",
    "agg_bureau['BUREAU_ACTIVE_DEBT_OVER_CREDIT'] = \\\n",
    "    agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e608929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, agg_bureau, on='SK_ID_CURR', how='left')\n",
    "del agg_bureau, bureau\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = pd.read_csv(os.path.join(DATA_DIRECTORY, 'previous_application.csv'))\n",
    "pay = pd.read_csv(os.path.join(DATA_DIRECTORY, 'installments_payments.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ffc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "    'RATE_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['max'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean', 'var'],\n",
    "    'DOWN_PAYMENT_TO_CREDIT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_ACTIVE_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'SIMPLE_INTERESTS': ['mean'],\n",
    "    'AMT_ANNUITY': ['max', 'sum'],\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'AMT_PAYMENT': ['sum'],\n",
    "    'INSTALMENT_PAYMENT_DIFF': ['mean', 'max'],\n",
    "    'REMAINING_DEBT': ['max', 'mean', 'sum'],\n",
    "    'REPAYMENT_RATIO': ['mean'],\n",
    "}\n",
    "PREVIOUS_LATE_PAYMENTS_AGG = {\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_LOAN_TYPE_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'mean', 'max', 'var'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['max'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['max', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_TIME_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['mean', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_APPROVED_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max'],\n",
    "    'AMT_GOODS_PRICE': ['max'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['mean'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['max'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    # The following features are only for approved applications\n",
    "    'DAYS_FIRST_DRAWING': ['max', 'mean'],\n",
    "    'DAYS_FIRST_DUE': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE': ['max', 'mean'],\n",
    "    'DAYS_LAST_DUE_DIFF': ['min', 'max', 'mean'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'max', 'mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_REFUSED_AGG = {\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = [\n",
    "    'NAME_CONTRACT_STATUS', 'NAME_CONTRACT_TYPE', 'CHANNEL_TYPE',\n",
    "    'NAME_TYPE_SUITE', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION',\n",
    "    'NAME_PRODUCT_TYPE', 'NAME_CLIENT_TYPE']\n",
    "prev, categorical_cols = one_hot_encoder(prev, ohe_columns, nan_as_category= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65397982",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev['APPLICATION_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
    "prev['APPLICATION_CREDIT_RATIO'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "prev['CREDIT_TO_ANNUITY_RATIO'] = prev['AMT_CREDIT']/prev['AMT_ANNUITY']\n",
    "prev['DOWN_PAYMENT_TO_CREDIT'] = prev['AMT_DOWN_PAYMENT'] / prev['AMT_CREDIT']\n",
    "total_payment = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
    "prev['SIMPLE_INTERESTS'] = (total_payment/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee33cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "active_df = approved[approved['DAYS_LAST_DUE'] == 365243]\n",
    "active_pay = pay[pay['SK_ID_PREV'].isin(active_df['SK_ID_PREV'])]\n",
    "active_pay_agg = active_pay.groupby('SK_ID_PREV')[['AMT_INSTALMENT', 'AMT_PAYMENT']].sum()\n",
    "active_pay_agg.reset_index(inplace= True)\n",
    "active_pay_agg['INSTALMENT_PAYMENT_DIFF'] = active_pay_agg['AMT_INSTALMENT'] - active_pay_agg['AMT_PAYMENT']\n",
    "active_df = active_df.merge(active_pay_agg, on= 'SK_ID_PREV', how= 'left')\n",
    "active_df['REMAINING_DEBT'] = active_df['AMT_CREDIT'] - active_df['AMT_PAYMENT']\n",
    "active_df['REPAYMENT_RATIO'] = active_df['AMT_PAYMENT'] / active_df['AMT_CREDIT']\n",
    "active_agg_df = group(active_df, 'PREV_ACTIVE_', PREVIOUS_ACTIVE_AGG)\n",
    "active_agg_df['TOTAL_REPAYMENT_RATIO'] = active_agg_df['PREV_ACTIVE_AMT_PAYMENT_SUM']/\\\n",
    "                                            active_agg_df['PREV_ACTIVE_AMT_CREDIT_SUM']\n",
    "del active_pay, active_pay_agg, active_df; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a695023",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad04139",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev['DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
    "approved['DAYS_LAST_DUE_DIFF'] = approved['DAYS_LAST_DUE_1ST_VERSION'] - approved['DAYS_LAST_DUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57992bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_agg = {key: ['mean'] for key in categorical_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f56373",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_prev = group(prev, 'PREV_', {**PREVIOUS_AGG, **categorical_agg})\n",
    "agg_prev = agg_prev.merge(active_agg_df, how='left', on='SK_ID_CURR')\n",
    "del active_agg_df; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_prev = group_and_merge(approved, agg_prev, 'APPROVED_', PREVIOUS_APPROVED_AGG)\n",
    "refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "agg_prev = group_and_merge(refused, agg_prev, 'REFUSED_', PREVIOUS_REFUSED_AGG)\n",
    "del approved, refused; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff61feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loan_type in ['Consumer loans', 'Cash loans']:\n",
    "    type_df = prev[prev['NAME_CONTRACT_TYPE_{}'.format(loan_type)] == 1]\n",
    "    prefix = 'PREV_' + loan_type.split(\" \")[0] + '_'\n",
    "    agg_prev = group_and_merge(type_df, agg_prev, prefix, PREVIOUS_LOAN_TYPE_AGG)\n",
    "    del type_df; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326cf2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay['LATE_PAYMENT'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n",
    "pay['LATE_PAYMENT'] = pay['LATE_PAYMENT'].apply(lambda x: 1 if x > 0 else 0)\n",
    "dpd_id = pay[pay['LATE_PAYMENT'] > 0]['SK_ID_PREV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae622c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dpd = group_and_merge(prev[prev['SK_ID_PREV'].isin(dpd_id)], agg_prev,\n",
    "                                    'PREV_LATE_', PREVIOUS_LATE_PAYMENTS_AGG)\n",
    "del agg_dpd, dpd_id; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_frame in [12, 24]:\n",
    "    time_frame_df = prev[prev['DAYS_DECISION'] >= -30*time_frame]\n",
    "    prefix = 'PREV_LAST{}M_'.format(time_frame)\n",
    "    agg_prev = group_and_merge(time_frame_df, agg_prev, prefix, PREVIOUS_TIME_AGG)\n",
    "    del time_frame_df; gc.collect()\n",
    "del prev; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, agg_prev, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48491447",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['TARGET'].notnull()]\n",
    "test = df[df['TARGET'].isnull()]\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d43b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['TARGET']\n",
    "train = train.drop(columns=['TARGET'])\n",
    "test = test.drop(columns=['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7481b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = list(train.columns)\n",
    "\n",
    "train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df = test.copy()\n",
    "train_df = train.copy()\n",
    "train_df['TARGET'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'median')\n",
    "imputer.fit(train)\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(C = 0.0001)\n",
    "log_reg.fit(train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecae7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pred = log_reg.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test_df[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('log_reg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea75ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.fit(train, labels)\n",
    "\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': feature, 'importance': feature_importance_values})\n",
    "\n",
    "predictions = random_forest.predict_proba(test)[:, 1]\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = test_df[['SK_ID_CURR']]\n",
    "submit['TARGET'] = predictions\n",
    "del predictions\n",
    "submit.to_csv('random_forest.csv', index = False)\n",
    "del submit\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "# Ref: https://pranaysite.netlify.app/lightgbm/\n",
    "\n",
    "def model(features, test_features, encoding = 'ohe', n_folds = 5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission, fi, metrics = model(train_df, test_df)\n",
    "print('LightGBM metrics')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf204a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(df):\n",
    "    \"\"\"\n",
    "    Plot importances returned by a model. This can work with any measure of\n",
    "    feature importance provided that higher importance is better. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): feature importances. Must have the features in a column\n",
    "        called `features` and the importances in a column called `importance\n",
    "        \n",
    "    Returns:\n",
    "        shows a plot of the 15 most importance features\n",
    "        \n",
    "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
    "        with a column for normalized importance\n",
    "        \"\"\"\n",
    "    \n",
    "    # Sort features according to importance\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    \n",
    "    # Normalize the feature importances to add up to one\n",
    "    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n",
    "\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:15]))), \n",
    "            df['importance_normalized'].head(15), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
    "    ax.set_yticklabels(df['feature'].head(15))\n",
    "    \n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba820e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_sorted = plot_feature_importances(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c759d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgb.csv', index = False)\n",
    "del submission, fi, fi_sorted, metrics\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = labels\n",
    "train_id = train_df['SK_ID_CURR']\n",
    "test_id = test_df['SK_ID_CURR']\n",
    "\n",
    "train_df_xg = train_df.copy()\n",
    "test_df_xg = test_df.copy()\n",
    "\n",
    "train_df_xg.drop('SK_ID_CURR', inplace=True, axis=1)\n",
    "test_df_xg.drop('SK_ID_CURR', inplace=True, axis=1)\n",
    "\n",
    "train_df_xg, test_df_xg = train_df_xg.align(test_df_xg, join = 'inner', axis = 1)\n",
    "\n",
    "ratio = (train_values == 0).sum()/ (train_values == 1).sum()\n",
    "del train_df, test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df_xg, train_values, test_size=0.2, stratify=train_values, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(n_estimators=1200, objective='binary:logistic', gamma=0.098, subsample=0.5, scale_pos_weight=ratio )\n",
    "clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='auc', early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5793d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test_df_xg.values)[:, 1]\n",
    "submission = pd.DataFrame({'SK_ID_CURR': test_id.values, 'TARGET': predictions})\n",
    "submission.to_csv('xgboost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d37c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_roc_curve(y_, oof_preds_, folds_idx_):\n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(6,6))\n",
    "    scores = [] \n",
    "    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n",
    "        # Plot the roc curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n",
    "        score = roc_auc_score(y_.iloc[val_idx], oof_preds_[val_idx])\n",
    "        scores.append(score)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Luck', alpha=.8)\n",
    "    fpr, tpr, thresholds = roc_curve(y_, oof_preds_)\n",
    "    score = roc_auc_score(y_, oof_preds_)\n",
    "    plt.plot(fpr, tpr, color='b',\n",
    "             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n",
    "             lw=2, alpha=.8)\n",
    "    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Embedding Neural Network ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def display_precision_recall(y_, oof_preds_, folds_idx_):\n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    scores = [] \n",
    "    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n",
    "        # Plot the roc curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n",
    "        score = average_precision_score(y_.iloc[val_idx], oof_preds_[val_idx])\n",
    "        scores.append(score)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='AP fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_, oof_preds_)\n",
    "    score = average_precision_score(y_, oof_preds_)\n",
    "    plt.plot(precision, recall, color='b',\n",
    "             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n",
    "             lw=2, alpha=.8)\n",
    "    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Embedding Neural Network Recall / Precision')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_dir, debug=False):\n",
    "    # No target encoding\n",
    "    num_rows = 10000 if debug else None\n",
    "    \n",
    "    print('Preprocessing started.')\n",
    "    print('Bureau_Balance')\n",
    "    buro_bal = pd.read_csv(input_dir + 'bureau_balance.csv', nrows=num_rows)\n",
    "    \n",
    "    buro_counts = buro_bal[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n",
    "    buro_bal['buro_count'] = buro_bal['SK_ID_BUREAU'].map(buro_counts['MONTHS_BALANCE'])\n",
    "    \n",
    "    avg_buro_bal = buro_bal.groupby('SK_ID_BUREAU').mean()\n",
    "    \n",
    "    avg_buro_bal.columns = ['avg_buro_' + f_ for f_ in avg_buro_bal.columns]\n",
    "    del buro_bal\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Bureau')\n",
    "    buro_full = pd.read_csv(input_dir + 'bureau.csv', nrows=num_rows)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    buro_full = buro_full.merge(right=avg_buro_bal.reset_index(), how='left', on='SK_ID_BUREAU', suffixes=('', '_bur_bal'))\n",
    "    \n",
    "    nb_bureau_per_curr = buro_full[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n",
    "    buro_full['SK_ID_BUREAU'] = buro_full['SK_ID_CURR'].map(nb_bureau_per_curr['SK_ID_BUREAU'])\n",
    "    \n",
    "    avg_buro = buro_full.groupby('SK_ID_CURR').mean()\n",
    "    \n",
    "    del buro_full\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Previous_Application')\n",
    "    prev = pd.read_csv(input_dir + 'previous_application.csv', nrows=num_rows)\n",
    "    \n",
    "    prev_cat_features = [\n",
    "        f_ for f_ in prev.columns if prev[f_].dtype == 'object'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    nb_prev_per_curr = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    prev['SK_ID_PREV'] = prev['SK_ID_CURR'].map(nb_prev_per_curr['SK_ID_PREV'])\n",
    "    \n",
    "    avg_prev = prev.groupby('SK_ID_CURR').mean()\n",
    "    del prev\n",
    "    gc.collect()\n",
    "    \n",
    "    print('POS_CASH_Balance')\n",
    "    pos = pd.read_csv(input_dir + 'POS_CASH_balance.csv', nrows=num_rows)\n",
    "    \n",
    "    \n",
    "    nb_prevs = pos[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    pos['SK_ID_PREV'] = pos['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "    \n",
    "    avg_pos = pos.groupby('SK_ID_CURR').mean()\n",
    "    \n",
    "    del pos, nb_prevs\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Credit_Card_Balance')\n",
    "    cc_bal = pd.read_csv(input_dir + 'credit_card_balance.csv', nrows=num_rows)\n",
    "\n",
    "    nb_prevs = cc_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    cc_bal['SK_ID_PREV'] = cc_bal['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "    \n",
    "    avg_cc_bal = cc_bal.groupby('SK_ID_CURR').mean()\n",
    "    avg_cc_bal.columns = ['cc_bal_' + f_ for f_ in avg_cc_bal.columns]\n",
    "    \n",
    "    del cc_bal, nb_prevs\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Installments_Payments')\n",
    "    inst = pd.read_csv(input_dir + 'installments_payments.csv', nrows=num_rows)\n",
    "    nb_prevs = inst[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    inst['SK_ID_PREV'] = inst['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "    \n",
    "    avg_inst = inst.groupby('SK_ID_CURR').mean()\n",
    "    avg_inst.columns = ['inst_' + f_ for f_ in avg_inst.columns]\n",
    "    \n",
    "    print('Train/Test')\n",
    "    data = pd.read_csv(input_dir + 'application_train.csv', nrows=num_rows)\n",
    "    test = pd.read_csv(input_dir + 'application_test.csv', nrows=num_rows)\n",
    "    print('Shapes : ', data.shape, test.shape)\n",
    "        \n",
    "    data = data.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    data = data.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    test = test.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    del avg_buro, avg_prev\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Preprocessing done.')\n",
    "\n",
    "    return data, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddecc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = preprocessing('../input/home-credit-default-risk/', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target and the ID\n",
    "X_train, y_train = train.iloc[:,2:], train.TARGET\n",
    "X_test = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_vals_dict = {c: list(X_train[c].unique()) for c in X_train.columns if X_train[c].dtype == object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_numeric   = len(X_train.columns) - len(col_vals_dict)\n",
    "nb_categoric = len(col_vals_dict)\n",
    "print('Number of Numerical features:', nb_numeric)\n",
    "print('Number of Categorical features:', nb_categoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455756e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the labels of each features\n",
    "col_vals_dict = {c: list(X_train[c].unique()) for c in X_train.columns if X_train[c].dtype == object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa216b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator to parse the cat\n",
    "generator = (c for c in X_train.columns if X_train[c].dtype == object)\n",
    "\n",
    "# Label Encoder\n",
    "for c in generator:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(X_train[c].values) + list(X_test[c].values))\n",
    "    X_train[c] = lbl.transform(list(X_train[c].values))\n",
    "    X_test[c] = lbl.transform(list(X_test[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols = []\n",
    "len_embed_cols = []\n",
    "for c in col_vals_dict:\n",
    "    if len(col_vals_dict[c])>2:\n",
    "        embed_cols.append(c)\n",
    "        len_embed_cols.append(len(col_vals_dict[c]))\n",
    "        print(c + ': %d values' % len(col_vals_dict[c])) #look at value counts to know the embedding dimensions\n",
    "        \n",
    "print('\\n Number of embed features :', len(embed_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_network(len_embed_cols):\n",
    "    \n",
    "    model_out = []\n",
    "    model_in  = []\n",
    "    \n",
    "    for dim in len_embed_cols:\n",
    "        input_dim = Input(shape=(1,), dtype='int32')\n",
    "        embed_dim = Embedding(dim, dim//2, input_length=1)(input_dim)\n",
    "        embed_dim = Dropout(0.25)(embed_dim)\n",
    "        embed_dim = Reshape((dim//2,))(embed_dim)\n",
    "        model_out.append(embed_dim)\n",
    "        model_in.append(input_dim)\n",
    "    \n",
    "    input_num = Input(shape=(176,), dtype='float32')\n",
    "    outputs = Concatenate(axis=1)([*model_out, input_num])\n",
    "    \n",
    "    outputs = (Dense(128))(outputs) \n",
    "    outputs = (Activation('relu'))(outputs)\n",
    "    outputs = (Dropout(.35))(outputs)\n",
    "    outputs = (Dense(64))(outputs)\n",
    "    outputs = (Activation('relu'))(outputs)\n",
    "    outputs = (Dropout(.15))(outputs)\n",
    "    outputs = (Dense(32))(outputs) \n",
    "    outputs = (Activation('relu'))(outputs)\n",
    "    outputs = (Dropout(.15))(outputs)\n",
    "    outputs = (Dense(1))(outputs)\n",
    "    outputs = (Activation('sigmoid'))(outputs)\n",
    "    \n",
    "    model = Model([*model_in, input_num], outputs)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(X_train, X_val, X_test):\n",
    "\n",
    "    input_list_train = []\n",
    "    input_list_val = []\n",
    "    input_list_test = []\n",
    "    \n",
    "    #the cols to be embedded: rescaling to range [0, # values)\n",
    "    for c in embed_cols:\n",
    "        raw_vals = np.unique(X_train[c])\n",
    "        val_map = {}\n",
    "        for i in range(len(raw_vals)):\n",
    "            val_map[raw_vals[i]] = i       \n",
    "        input_list_train.append(X_train[c].map(val_map).values)\n",
    "        input_list_val.append(X_val[c].map(val_map).fillna(0).values)\n",
    "        input_list_test.append(X_test[c].map(val_map).fillna(0).values)\n",
    "        \n",
    "    #the rest of the columns\n",
    "    other_cols = [c for c in X_train.columns if (not c in embed_cols)]\n",
    "    input_list_train.append(X_train[other_cols].values)\n",
    "    input_list_val.append(X_val[other_cols].values)\n",
    "    input_list_test.append(X_test[other_cols].values)\n",
    "    \n",
    "    return input_list_train, input_list_val, input_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbc9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(X_train, X_train, X_test)\n",
    "print('Length of the list:', len(proc_X_train_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc35a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_X_train_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47703e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc_X_train_f[12].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3584fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del proc_X_train_f, proc_X_val_f, proc_X_test_f\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [x for x in X_train.columns if x not in embed_cols]\n",
    "\n",
    "\n",
    "# Impute missing values in order to scale\n",
    "X_train[num_cols] = X_train[num_cols].fillna(value = 0)\n",
    "X_test[num_cols] = X_test[num_cols].fillna(value = 0)\n",
    "\n",
    "# Fit the scaler only on train data\n",
    "scaler = MinMaxScaler().fit(X_train[num_cols])\n",
    "X_train.loc[:,num_cols] = scaler.transform(X_train[num_cols])\n",
    "X_test.loc[:,num_cols] = scaler.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "runs_per_fold = 1\n",
    "n_epochs = 250\n",
    "patience = 10\n",
    "\n",
    "cv_aucs   = []\n",
    "full_val_preds = np.zeros(np.shape(X_train)[0])\n",
    "y_preds = np.zeros((np.shape(X_test)[0],K))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = K,  \n",
    "                            shuffle = True, random_state=1)\n",
    "\n",
    "for i, (f_ind, outf_ind) in enumerate(kfold.split(X_train, y_train)):\n",
    "\n",
    "    X_train_f, X_val_f = X_train.loc[f_ind].copy(), X_train.loc[outf_ind].copy()\n",
    "    y_train_f, y_val_f = y_train[f_ind], y_train[outf_ind]\n",
    "    \n",
    "    X_test_f = X_test.copy()\n",
    "    \n",
    "    \n",
    "    # Shuffle data\n",
    "    idx = np.arange(len(X_train_f))\n",
    "    np.random.shuffle(idx)\n",
    "    X_train_f = X_train_f.iloc[idx]\n",
    "    y_train_f = y_train_f.iloc[idx]\n",
    "    \n",
    "    #preprocessing\n",
    "    proc_X_train_f, proc_X_val_f, proc_X_test_f = preproc(X_train_f, X_val_f, X_test_f)\n",
    "    \n",
    "    #track oof prediction for cv scores\n",
    "    val_preds = 0\n",
    "    \n",
    "    for j in range(runs_per_fold):\n",
    "    \n",
    "        NN = build_embedding_network(len_embed_cols)\n",
    "\n",
    "        # Set callback functions to early stop training and save the best model so far\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "\n",
    "        NN.fit(proc_X_train_f, y_train_f.values, epochs=n_epochs, batch_size=4096, verbose=1,callbacks=callbacks,validation_data=(proc_X_val_f, y_val_f))\n",
    "        \n",
    "        val_preds += NN.predict(proc_X_val_f)[:,0] / runs_per_fold\n",
    "        y_preds[:,i] += NN.predict(proc_X_test_f)[:,0] / runs_per_fold\n",
    "        \n",
    "    full_val_preds[outf_ind] += val_preds\n",
    "        \n",
    "    cv_auc  = roc_auc_score(y_val_f.values, val_preds)\n",
    "    cv_aucs.append(cv_auc)\n",
    "    print ('\\nFold %i prediction cv AUC: %.5f\\n' %(i,cv_auc))\n",
    "    \n",
    "print('Mean out of fold AUC: %.5f' % np.mean(cv_auc))\n",
    "print('Full validation AUC: %.5f' % roc_auc_score(y_train.values, full_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_idx = [(trn_idx, val_idx) for trn_idx, val_idx in kfold.split(X_train, y_train)]\n",
    "display_roc_curve(y_=y_train, oof_preds_=full_val_preds, folds_idx_=folds_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6de603",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(y_=y_train, oof_preds_=full_val_preds, folds_idx_=folds_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87791ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['TARGET'] = np.mean(y_preds, axis=1)\n",
    "test = test[['SK_ID_CURR', 'TARGET']]\n",
    "out_df = pd.DataFrame({'SK_ID_CURR': test['SK_ID_CURR'], 'TARGET': test['TARGET']})\n",
    "out_df.to_csv('nn_embedding_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2286.78096,
   "end_time": "2021-07-24T19:20:44.628003",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-24T18:42:37.847043",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
