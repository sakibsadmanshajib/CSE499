{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv'))\n",
    "labels = pd.read_csv(os.path.join(DATA_DIRECTORY, 'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train['SK_ID_CURR']\n",
    "train.drop('SK_ID_CURR', axis=1, inplace=True)\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'median')\n",
    "imputer.fit(train)\n",
    "train = imputer.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features, test_features, labels, test_ids, n_folds = 5):\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 8888)\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    ratio = (labels == 0).sum()/ (labels == 1).sum()\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = XGBClassifier(\n",
    "                  n_estimators=5000,\n",
    "                  learning_rate=0.01,\n",
    "                  max_depth=11,\n",
    "                  objective='binary:logistic', \n",
    "                  gamma=0.098, \n",
    "                  subsample=0.708,\n",
    "                  reg_alpha=3.564, \n",
    "                  reg_lambda=4.930,\n",
    "                  random_state=8888,\n",
    "                  seed=88888,\n",
    "                  scale_pos_weight=ratio,\n",
    "                  colsample_bytree= 0.613,\n",
    "                  min_child_weight= 6,\n",
    "                  tree_method='gpu_hist',\n",
    "                  predictor='gpu_predictor'\n",
    "                  )\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  early_stopping_rounds = 2500, verbose = 1000)\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features)[:, 1]\n",
    "        \n",
    "        evals_result = model.evals_result()\n",
    "        valid_score = max(evals_result['validation_1']['auc'])\n",
    "        train_score = max(evals_result['validation_0']['auc'])\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission, metrics = model(train, train, labels, train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('XGBoost metrics')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('xgboost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = submission['TARGET'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(labels[:,0],  pred)\n",
    "auc = roc_auc_score(labels[:,0], pred)\n",
    "plt.plot(fpr,tpr,label=\"XGBoost\")\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  \n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "home_credit_loan_xgboost-with-kfolds.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b2acef9c405ed574e8ba965b223740abc6391b41de725cf0c976ada615306344"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('CSE499': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
