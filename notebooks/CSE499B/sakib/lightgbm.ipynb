{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import gc\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "import lightgbm as lgb\r\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1adc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['TARGET'].notnull()]\r\n",
    "test = df[df['TARGET'].isnull()]\r\n",
    "del df\r\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c45be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['TARGET']\r\n",
    "train = train.drop(columns=['TARGET'])\r\n",
    "test = test.drop(columns=['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48602f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = list(train.columns)\r\n",
    "\r\n",
    "test_df = test.copy()\r\n",
    "train_df = train.copy()\r\n",
    "train_df['TARGET'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://pranaysite.netlify.app/lightgbm/\r\n",
    "\r\n",
    "def model(features, test_features, encoding = 'ohe', n_folds = 5):\r\n",
    "    \r\n",
    "    \"\"\"Train and test a light gradient boosting model using\r\n",
    "    cross validation. \r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    --------\r\n",
    "        features (pd.DataFrame): \r\n",
    "            dataframe of training features to use \r\n",
    "            for training a model. Must include the TARGET column.\r\n",
    "        test_features (pd.DataFrame): \r\n",
    "            dataframe of testing features to use\r\n",
    "            for making predictions with the model. \r\n",
    "        encoding (str, default = 'ohe'): \r\n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\r\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\r\n",
    "        \r\n",
    "    Return\r\n",
    "    --------\r\n",
    "        submission (pd.DataFrame): \r\n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\r\n",
    "            predicted by the model.\r\n",
    "        feature_importances (pd.DataFrame): \r\n",
    "            dataframe with the feature importances from the model.\r\n",
    "        valid_metrics (pd.DataFrame): \r\n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\r\n",
    "        \r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # Extract the ids\r\n",
    "    train_ids = features['SK_ID_CURR']\r\n",
    "    test_ids = test_features['SK_ID_CURR']\r\n",
    "    \r\n",
    "    # Extract the labels for training\r\n",
    "    labels = features['TARGET']\r\n",
    "    \r\n",
    "    # Remove the ids and target\r\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\r\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\r\n",
    "    \r\n",
    "    \r\n",
    "    # One Hot Encoding\r\n",
    "    if encoding == 'ohe':\r\n",
    "        features = pd.get_dummies(features)\r\n",
    "        test_features = pd.get_dummies(test_features)\r\n",
    "        \r\n",
    "        # Align the dataframes by the columns\r\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\r\n",
    "        \r\n",
    "        # No categorical indices to record\r\n",
    "        cat_indices = 'auto'\r\n",
    "    \r\n",
    "    # Integer label encoding\r\n",
    "    elif encoding == 'le':\r\n",
    "        \r\n",
    "        # Create a label encoder\r\n",
    "        label_encoder = LabelEncoder()\r\n",
    "        \r\n",
    "        # List for storing categorical indices\r\n",
    "        cat_indices = []\r\n",
    "        \r\n",
    "        # Iterate through each column\r\n",
    "        for i, col in enumerate(features):\r\n",
    "            if features[col].dtype == 'object':\r\n",
    "                # Map the categorical features to integers\r\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\r\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\r\n",
    "\r\n",
    "                # Record the categorical indices\r\n",
    "                cat_indices.append(i)\r\n",
    "    \r\n",
    "    # Catch error if label encoding scheme is not valid\r\n",
    "    else:\r\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\r\n",
    "        \r\n",
    "    print('Training Data Shape: ', features.shape)\r\n",
    "    print('Testing Data Shape: ', test_features.shape)\r\n",
    "    \r\n",
    "    # Extract feature names\r\n",
    "    feature_names = list(features.columns)\r\n",
    "    \r\n",
    "    # Convert to np arrays\r\n",
    "    features = np.array(features)\r\n",
    "    test_features = np.array(test_features)\r\n",
    "    \r\n",
    "    # Create the kfold object\r\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\r\n",
    "    \r\n",
    "    # Empty array for feature importances\r\n",
    "    feature_importance_values = np.zeros(len(feature_names))\r\n",
    "    \r\n",
    "    # Empty array for test predictions\r\n",
    "    test_predictions = np.zeros(test_features.shape[0])\r\n",
    "    \r\n",
    "    # Empty array for out of fold validation predictions\r\n",
    "    out_of_fold = np.zeros(features.shape[0])\r\n",
    "    \r\n",
    "    # Lists for recording validation and training scores\r\n",
    "    valid_scores = []\r\n",
    "    train_scores = []\r\n",
    "    \r\n",
    "    # Iterate through each fold\r\n",
    "    for train_indices, valid_indices in k_fold.split(features):\r\n",
    "        \r\n",
    "        # Training data for the fold\r\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\r\n",
    "        # Validation data for the fold\r\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\r\n",
    "        \r\n",
    "        # Create the model\r\n",
    "        model = lgb.LGBMClassifier(n_estimators=100000, objective = 'binary', \r\n",
    "                                   class_weight = 'balanced', learning_rate = 0.02, \r\n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \r\n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 100)\r\n",
    "        \r\n",
    "        # Train the model\r\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\r\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\r\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\r\n",
    "                  early_stopping_rounds = 100, verbose = 200)\r\n",
    "        \r\n",
    "        # Record the best iteration\r\n",
    "        best_iteration = model.best_iteration_\r\n",
    "        \r\n",
    "        # Record the feature importances\r\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\r\n",
    "        \r\n",
    "        # Make predictions\r\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\r\n",
    "        \r\n",
    "        # Record the out of fold predictions\r\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\r\n",
    "        \r\n",
    "        # Record the best score\r\n",
    "        valid_score = model.best_score_['valid']['auc']\r\n",
    "        train_score = model.best_score_['train']['auc']\r\n",
    "        \r\n",
    "        valid_scores.append(valid_score)\r\n",
    "        train_scores.append(train_score)\r\n",
    "        \r\n",
    "        # Clean up memory\r\n",
    "        gc.enable()\r\n",
    "        del model, train_features, valid_features\r\n",
    "        gc.collect()\r\n",
    "        \r\n",
    "    # Make the submission dataframe\r\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\r\n",
    "    \r\n",
    "    # Make the feature importance dataframe\r\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\r\n",
    "    \r\n",
    "    # Overall validation score\r\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\r\n",
    "    \r\n",
    "    # Add the overall scores to the metrics\r\n",
    "    valid_scores.append(valid_auc)\r\n",
    "    train_scores.append(np.mean(train_scores))\r\n",
    "    \r\n",
    "    # Needed for creating dataframe of validation scores\r\n",
    "    fold_names = list(range(n_folds))\r\n",
    "    fold_names.append('overall')\r\n",
    "    \r\n",
    "    # Dataframe of validation scores\r\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\r\n",
    "                            'train': train_scores,\r\n",
    "                            'valid': valid_scores}) \r\n",
    "    \r\n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03da7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission, fi, metrics = model(train_df, test_df, n_folds=10)\r\n",
    "print('LightGBM metrics')\r\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ebc772",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgb_10fold.csv', index = False)\r\n",
    "del submission, fi, metrics\r\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit home-credit-default-risk -f lgb_10fold.csv -m \"Notebook Home Credit Loan | 10 Folds | LightGBM\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
