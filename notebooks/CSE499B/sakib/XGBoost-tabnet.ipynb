{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.0 64-bit ('CSE499': conda)"},"language_info":{"name":"python","version":"3.8.0","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"b2acef9c405ed574e8ba965b223740abc6391b41de725cf0c976ada615306344"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":1,"source":["import os\r\n","import pandas as pd\r\n","import numpy as np\r\n","import warnings\r\n","from sklearn.model_selection import KFold\r\n","from sklearn.metrics import roc_auc_score\r\n","from xgboost import XGBClassifier\r\n","from sklearn.impute import SimpleImputer\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","import gc\r\n","warnings.simplefilter(action='ignore', category=FutureWarning)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:28:21.494147Z","iopub.execute_input":"2021-08-15T10:28:21.494583Z","iopub.status.idle":"2021-08-15T10:28:21.501491Z","shell.execute_reply.started":"2021-08-15T10:28:21.494549Z","shell.execute_reply":"2021-08-15T10:28:21.500260Z"},"trusted":true}},{"cell_type":"code","execution_count":2,"source":["DATA_DIRECTORY = \"\""],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:28:21.503344Z","iopub.execute_input":"2021-08-15T10:28:21.503869Z","iopub.status.idle":"2021-08-15T10:28:21.514538Z","shell.execute_reply.started":"2021-08-15T10:28:21.503824Z","shell.execute_reply":"2021-08-15T10:28:21.513573Z"},"trusted":true}},{"cell_type":"code","execution_count":3,"source":["train = pd.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv'))\r\n","test = pd.read_csv(os.path.join(DATA_DIRECTORY, 'test.csv'))\r\n","labels = pd.read_csv(os.path.join(DATA_DIRECTORY, 'labels.csv'))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:28:21.516002Z","iopub.execute_input":"2021-08-15T10:28:21.516426Z","iopub.status.idle":"2021-08-15T10:28:44.028830Z","shell.execute_reply.started":"2021-08-15T10:28:21.516384Z","shell.execute_reply":"2021-08-15T10:28:44.027899Z"},"trusted":true}},{"cell_type":"code","execution_count":4,"source":["labels = labels.to_numpy()\r\n","test_id = test['SK_ID_CURR']\r\n","train_id = train['SK_ID_CURR']"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-15T10:28:44.030478Z","iopub.execute_input":"2021-08-15T10:28:44.031094Z","iopub.status.idle":"2021-08-15T10:28:44.035762Z","shell.execute_reply.started":"2021-08-15T10:28:44.031046Z","shell.execute_reply":"2021-08-15T10:28:44.034723Z"},"trusted":true}},{"cell_type":"code","execution_count":5,"source":["train = train.drop(['SK_ID_CURR'], axis=1)\r\n","test = test.drop(['SK_ID_CURR'], axis=1)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["imputer = SimpleImputer(strategy = 'median')\r\n","imputer.fit(train)\r\n","train = imputer.transform(train)\r\n","test = imputer.transform(test)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["scaler = MinMaxScaler(feature_range = (0, 1))\r\n","scaler.fit(train)\r\n","train = scaler.transform(train)\r\n","test = scaler.transform(test)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["def model(features, test_features, labels, test_ids, n_folds = 5):\r\n","        \r\n","    print('Training Data Shape: ', features.shape)\r\n","    print('Testing Data Shape: ', test_features.shape)\r\n","    \r\n","    # Create the kfold object\r\n","    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 8888)\r\n","    \r\n","    # Empty array for test predictions\r\n","    test_predictions = np.zeros(test_features.shape[0])\r\n","    \r\n","    # Empty array for out of fold validation predictions\r\n","    out_of_fold = np.zeros(features.shape[0])\r\n","    \r\n","    # Lists for recording validation and training scores\r\n","    valid_scores = []\r\n","    train_scores = []\r\n","\r\n","    ratio = (labels == 0).sum()/ (labels == 1).sum()\r\n","    \r\n","    # Iterate through each fold\r\n","    for train_indices, valid_indices in k_fold.split(features):\r\n","        \r\n","        # Training data for the fold\r\n","        train_features, train_labels = features[train_indices], labels[train_indices]\r\n","        # Validation data for the fold\r\n","        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\r\n","        \r\n","        # Create the model\r\n","        model = XGBClassifier(\r\n","                  n_estimators=5000,\r\n","                  learning_rate=0.01,\r\n","                  max_depth=11,\r\n","                  objective='binary:logistic', \r\n","                  gamma=0.098, \r\n","                  subsample=0.708,\r\n","                  reg_alpha=3.564, \r\n","                  reg_lambda=4.930,\r\n","                  random_state=8888,\r\n","                  seed=88888,\r\n","                  scale_pos_weight=ratio,\r\n","                  colsample_bytree= 0.613,\r\n","                  min_child_weight= 6,\r\n","                  tree_method='gpu_hist',\r\n","                  predictor='gpu_predictor'\r\n","                  )\r\n","        \r\n","        # Train the model\r\n","        model.fit(train_features, train_labels, eval_metric = 'auc',\r\n","                  eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\r\n","                  early_stopping_rounds = 2500, verbose = 1000)\r\n","        \r\n","        # Make predictions\r\n","        test_predictions += model.predict_proba(test_features)[:, 1] / k_fold.n_splits\r\n","        \r\n","        # Record the out of fold predictions\r\n","        out_of_fold[valid_indices] = model.predict_proba(valid_features)[:, 1]\r\n","        \r\n","        evals_result = model.evals_result()\r\n","        valid_score = max(evals_result['validation_1']['auc'])\r\n","        train_score = max(evals_result['validation_0']['auc'])\r\n","        \r\n","        valid_scores.append(valid_score)\r\n","        train_scores.append(train_score)\r\n","        \r\n","        # Clean up memory\r\n","        gc.enable()\r\n","        del model, train_features, valid_features\r\n","        gc.collect()\r\n","        \r\n","    # Make the submission dataframe\r\n","    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\r\n","    \r\n","    # Overall validation score\r\n","    valid_auc = roc_auc_score(labels, out_of_fold)\r\n","    \r\n","    # Add the overall scores to the metrics\r\n","    valid_scores.append(valid_auc)\r\n","    train_scores.append(np.mean(train_scores))\r\n","    \r\n","    # Needed for creating dataframe of validation scores\r\n","    fold_names = list(range(n_folds))\r\n","    fold_names.append('overall')\r\n","    \r\n","    # Dataframe of validation scores\r\n","    metrics = pd.DataFrame({'fold': fold_names,\r\n","                            'train': train_scores,\r\n","                            'valid': valid_scores}) \r\n","    \r\n","    return submission, metrics"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["submission, metrics = model(train, train, labels, train_id)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Training Data Shape:  (307506, 649)\n","Testing Data Shape:  (307506, 649)\n"]},{"output_type":"stream","name":"stderr","text":["C:\\Users\\sakib\\anaconda3\\envs\\CSE499\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","C:\\Users\\sakib\\anaconda3\\envs\\CSE499\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  return f(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["[0]\tvalidation_0-auc:0.79603\tvalidation_1-auc:0.69395\n","[1000]\tvalidation_0-auc:0.99274\tvalidation_1-auc:0.79005\n","[2000]\tvalidation_0-auc:0.99952\tvalidation_1-auc:0.78887\n","[3000]\tvalidation_0-auc:0.99997\tvalidation_1-auc:0.78836\n","[3359]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.78848\n","[0]\tvalidation_0-auc:0.79744\tvalidation_1-auc:0.68108\n","[1000]\tvalidation_0-auc:0.99308\tvalidation_1-auc:0.78418\n","[2000]\tvalidation_0-auc:0.99957\tvalidation_1-auc:0.78365\n","[3000]\tvalidation_0-auc:0.99997\tvalidation_1-auc:0.78333\n","[3651]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.78344\n","[0]\tvalidation_0-auc:0.79517\tvalidation_1-auc:0.68705\n","[1000]\tvalidation_0-auc:0.99313\tvalidation_1-auc:0.78805\n","[2000]\tvalidation_0-auc:0.99960\tvalidation_1-auc:0.78692\n","[3000]\tvalidation_0-auc:0.99998\tvalidation_1-auc:0.78678\n","[3582]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.78690\n","[0]\tvalidation_0-auc:0.79514\tvalidation_1-auc:0.68986\n","[1000]\tvalidation_0-auc:0.99341\tvalidation_1-auc:0.78994\n","[2000]\tvalidation_0-auc:0.99960\tvalidation_1-auc:0.78823\n","[3000]\tvalidation_0-auc:0.99997\tvalidation_1-auc:0.78786\n","[3285]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.78800\n","[0]\tvalidation_0-auc:0.79356\tvalidation_1-auc:0.68134\n","[1000]\tvalidation_0-auc:0.99282\tvalidation_1-auc:0.78263\n","[2000]\tvalidation_0-auc:0.99953\tvalidation_1-auc:0.78127\n","[3000]\tvalidation_0-auc:0.99997\tvalidation_1-auc:0.78110\n","[3652]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.78182\n"]}],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["submission = submission['TARGET'].to_numpy()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["from sklearn.metrics import roc_curve"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["fpr, tpr, thresholds = roc_curve(labels, submission)\r\n","# Calculate the G-mean\r\n","gmean = np.sqrt(tpr * (1 - fpr))\r\n","\r\n","# Find the optimal threshold\r\n","index = np.argmax(gmean)\r\n","bestThreshold = thresholds[index]"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["target = np.where(submission > bestThreshold, 1, 0)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["del fpr, gmean, imputer, index, DATA_DIRECTORY, thresholds, tpr, submission, metrics, bestThreshold\r\n","gc.collect()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["558"]},"metadata":{},"execution_count":14}],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["from pytorch_tabnet.tab_model import TabNetClassifier\r\n","import torch"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":16,"source":["def model(features, test_features, labels, test_ids, n_folds = 5):\r\n","        \r\n","    print('Training Data Shape: ', features.shape)\r\n","    print('Testing Data Shape: ', test_features.shape)\r\n","    \r\n","    # Create the kfold object\r\n","    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 88)\r\n","    \r\n","    # Empty array for test predictions\r\n","    test_predictions = np.zeros(test_features.shape[0])\r\n","    \r\n","    # Empty array for out of fold validation predictions\r\n","    out_of_fold = np.zeros(features.shape[0])\r\n","    \r\n","    # Lists for recording validation and training scores\r\n","    valid_scores = []\r\n","    train_scores = []\r\n","\r\n","    # Iterate through each fold\r\n","    for train_indices, valid_indices in k_fold.split(features):\r\n","        \r\n","        # Training data for the fold\r\n","        train_features, train_labels = features[train_indices], labels[train_indices]\r\n","        # Validation data for the fold\r\n","        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\r\n","\r\n","        # Create the model\r\n","        model = TabNetClassifier(\r\n","                    n_d=32, \r\n","                    n_a=32, \r\n","                    n_steps=10,\r\n","                    gamma=0.098, \r\n","                    n_independent=2, \r\n","                    n_shared=2,\r\n","                    lambda_sparse=1e-3, \r\n","                    momentum=0.4, \r\n","                    clip_value=2.,\r\n","                    optimizer_fn=torch.optim.Adam,\r\n","                    scheduler_params = {\"gamma\": 0.95,\r\n","                                    \"step_size\": 20},\r\n","                    optimizer_params=dict(lr=2e-2),\r\n","                    scheduler_fn=torch.optim.lr_scheduler.StepLR, \r\n","                    epsilon=1e-15, verbose = 0,\r\n","                    device_name='cuda'\r\n","                )\r\n","        \r\n","        # Train the model\r\n","        model.fit(\r\n","            train_features, train_labels,\r\n","            eval_set=[(train_features, train_labels), (valid_features, valid_labels)],  \r\n","            eval_name=['train', 'valid'],\r\n","            eval_metric=['auc'],\r\n","            max_epochs=1000 , patience=50,\r\n","            batch_size=1024, virtual_batch_size=128,\r\n","            num_workers=0,\r\n","            weights=1,\r\n","            drop_last=False\r\n","        )\r\n","\r\n","        print(model)\r\n","        \r\n","        # Make predictions\r\n","        test_predictions += model.predict_proba(test_features)[:, 1] / k_fold.n_splits\r\n","        \r\n","        # Record the out of fold predictions\r\n","        out_of_fold[valid_indices] = model.predict_proba(valid_features)[:, 1]\r\n","\r\n","        # Record the best score\r\n","        valid_score = roc_auc_score(valid_labels, model.predict(valid_features))\r\n","        train_score = roc_auc_score(train_labels, model.predict(train_features))\r\n","        \r\n","        valid_scores.append(valid_score)\r\n","        train_scores.append(train_score)\r\n","        \r\n","        # Clean up memory\r\n","        gc.enable()\r\n","        del model, train_features, valid_features\r\n","        gc.collect()\r\n","        \r\n","    # Make the submission dataframe\r\n","    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\r\n","    \r\n","    # Overall validation score\r\n","    valid_auc = roc_auc_score(labels, out_of_fold)\r\n","    \r\n","    # Add the overall scores to the metrics\r\n","    valid_scores.append(valid_auc)\r\n","    train_scores.append(np.mean(train_scores))\r\n","    \r\n","    # Needed for creating dataframe of validation scores\r\n","    fold_names = list(range(n_folds))\r\n","    fold_names.append('overall')\r\n","    \r\n","    # Dataframe of validation scores\r\n","    metrics = pd.DataFrame({'fold': fold_names,\r\n","                            'train': train_scores,\r\n","                            'valid': valid_scores}) \r\n","    \r\n","    return submission, metrics"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["submission, metrics = model(train, train, target, train_id)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Training Data Shape:  (307506, 649)\n","Testing Data Shape:  (307506, 649)\n","\n","Early stopping occurred at epoch 52 with best_epoch = 2 and best_valid_auc = 0.90614\n","Best weights from best epoch are automatically used!\n","TabNetClassifier(n_d=32, n_a=32, n_steps=10, gamma=0.098, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.4, lambda_sparse=0.001, seed=0, clip_value=2.0, verbose=0, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, scheduler_params={'gamma': 0.95, 'step_size': 20}, mask_type='sparsemax', input_dim=649, output_dim=2, device_name='cuda')\n","\n","Early stopping occurred at epoch 54 with best_epoch = 4 and best_valid_auc = 0.899\n","Best weights from best epoch are automatically used!\n","TabNetClassifier(n_d=32, n_a=32, n_steps=10, gamma=0.098, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.4, lambda_sparse=0.001, seed=0, clip_value=2.0, verbose=0, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, scheduler_params={'gamma': 0.95, 'step_size': 20}, mask_type='sparsemax', input_dim=649, output_dim=2, device_name='cuda')\n","\n","Early stopping occurred at epoch 52 with best_epoch = 2 and best_valid_auc = 0.90196\n","Best weights from best epoch are automatically used!\n","TabNetClassifier(n_d=32, n_a=32, n_steps=10, gamma=0.098, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.4, lambda_sparse=0.001, seed=0, clip_value=2.0, verbose=0, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, scheduler_params={'gamma': 0.95, 'step_size': 20}, mask_type='sparsemax', input_dim=649, output_dim=2, device_name='cuda')\n","\n","Early stopping occurred at epoch 53 with best_epoch = 3 and best_valid_auc = 0.90387\n","Best weights from best epoch are automatically used!\n","TabNetClassifier(n_d=32, n_a=32, n_steps=10, gamma=0.098, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.4, lambda_sparse=0.001, seed=0, clip_value=2.0, verbose=0, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, scheduler_params={'gamma': 0.95, 'step_size': 20}, mask_type='sparsemax', input_dim=649, output_dim=2, device_name='cuda')\n","\n","Early stopping occurred at epoch 53 with best_epoch = 3 and best_valid_auc = 0.9053\n","Best weights from best epoch are automatically used!\n","TabNetClassifier(n_d=32, n_a=32, n_steps=10, gamma=0.098, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.4, lambda_sparse=0.001, seed=0, clip_value=2.0, verbose=0, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=<class 'torch.optim.lr_scheduler.StepLR'>, scheduler_params={'gamma': 0.95, 'step_size': 20}, mask_type='sparsemax', input_dim=649, output_dim=2, device_name='cuda')\n"]}],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["print('TabNet metrics')\r\n","print(metrics)"],"outputs":[{"output_type":"stream","name":"stdout","text":["TabNet metrics\n","      fold     train     valid\n","0        0  0.839724  0.826682\n","1        1  0.865540  0.818954\n","2        2  0.836900  0.824502\n","3        3  0.850394  0.821780\n","4        4  0.850088  0.825996\n","5  overall  0.848529  0.901817\n"]}],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["from sklearn.preprocessing import MinMaxScaler\r\n","scaler = MinMaxScaler()\r\n","tn = submission['TARGET'].to_numpy().reshape(-1, 1)\r\n","scaler.fit(tn)\r\n","tg = scaler.transform(tn)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":20,"source":["submission = pd.DataFrame({'SK_ID_CURR': test_id, 'TARGET': tg[:,0]})"],"outputs":[{"output_type":"error","ename":"ValueError","evalue":"array length 307506 does not match index length 48744","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-20-6cffe9fe8afb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'SK_ID_CURR'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TARGET'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\anaconda3\\envs\\CSE499\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\CSE499\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n","\u001b[1;32m~\\anaconda3\\envs\\CSE499\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\CSE499\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    647\u001b[0m                         \u001b[1;34mf\"length {len(index)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m                     )\n\u001b[1;32m--> 649\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: array length 307506 does not match index length 48744"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["submission.to_csv('xgboost-tabnet.csv', index = False)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["pred = submission['TARGET'].to_numpy()\r\n","import matplotlib.pyplot as plt\r\n","\r\n","fpr, tpr, _ = roc_curve(labels[:,0],  pred)\r\n","auc = roc_auc_score(labels[:,0], pred)\r\n","plt.plot(fpr,tpr,label=\"XGBoost-TabNet\")\r\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  \r\n","plt.legend(loc=4)\r\n","plt.show()"],"outputs":[],"metadata":{}}]}