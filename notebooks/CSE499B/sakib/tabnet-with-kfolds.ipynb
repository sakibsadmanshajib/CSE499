{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.0 64-bit ('CSE499': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "b2acef9c405ed574e8ba965b223740abc6391b41de725cf0c976ada615306344"
    },
    "colab": {
      "name": "home-credit-loan-xgboost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import gc\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import warnings\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "import torch\r\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-15T08:41:19.429452Z",
          "iopub.execute_input": "2021-08-15T08:41:19.429937Z",
          "iopub.status.idle": "2021-08-15T08:41:20.637120Z",
          "shell.execute_reply.started": "2021-08-15T08:41:19.429814Z",
          "shell.execute_reply": "2021-08-15T08:41:20.636179Z"
        },
        "trusted": true,
        "id": "rT6tZDajOPdV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "DATA_DIRECTORY = \"\""
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-15T08:41:20.638860Z",
          "iopub.execute_input": "2021-08-15T08:41:20.639152Z",
          "iopub.status.idle": "2021-08-15T08:41:20.643250Z",
          "shell.execute_reply.started": "2021-08-15T08:41:20.639125Z",
          "shell.execute_reply": "2021-08-15T08:41:20.641920Z"
        },
        "trusted": true,
        "id": "ZqorwqXyOPdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train = pd.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv'))\r\n",
        "test = pd.read_csv(os.path.join(DATA_DIRECTORY, 'test.csv'))\r\n",
        "labels = pd.read_csv(os.path.join(DATA_DIRECTORY, 'labels.csv'))"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-15T08:41:20.645625Z",
          "iopub.execute_input": "2021-08-15T08:41:20.646034Z",
          "iopub.status.idle": "2021-08-15T08:41:53.075186Z",
          "shell.execute_reply.started": "2021-08-15T08:41:20.645992Z",
          "shell.execute_reply": "2021-08-15T08:41:53.074099Z"
        },
        "trusted": true,
        "id": "x7dfPNFcOPdY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_ids = test['SK_ID_CURR']\r\n",
        "train.drop('SK_ID_CURR', axis=1, inplace=True)\r\n",
        "test.drop('SK_ID_CURR', axis=1, inplace=True)\r\n",
        "labels = labels.to_numpy()"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-15T08:41:53.077155Z",
          "iopub.execute_input": "2021-08-15T08:41:53.077585Z",
          "iopub.status.idle": "2021-08-15T08:41:54.710215Z",
          "shell.execute_reply.started": "2021-08-15T08:41:53.077549Z",
          "shell.execute_reply": "2021-08-15T08:41:54.709307Z"
        },
        "trusted": true,
        "id": "jRkSRziYOPdY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "imputer = SimpleImputer(strategy = 'median')\r\n",
        "imputer.fit(train)\r\n",
        "train = imputer.transform(train)\r\n",
        "test = imputer.transform(test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ecyvB0DTSDS3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scaler = MinMaxScaler(feature_range = (0, 1))\r\n",
        "scaler.fit(train)\r\n",
        "train = scaler.transform(train)\r\n",
        "test = scaler.transform(test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xWgCl13jSBI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def model(features, test_features, labels, test_ids, n_folds = 5):\r\n",
        "        \r\n",
        "    print('Training Data Shape: ', features.shape)\r\n",
        "    print('Testing Data Shape: ', test_features.shape)\r\n",
        "    \r\n",
        "    # Create the kfold object\r\n",
        "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\r\n",
        "    \r\n",
        "    # Empty array for test predictions\r\n",
        "    test_predictions = np.zeros(test_features.shape[0])\r\n",
        "    \r\n",
        "    # Empty array for out of fold validation predictions\r\n",
        "    out_of_fold = np.zeros(features.shape[0])\r\n",
        "    \r\n",
        "    # Lists for recording validation and training scores\r\n",
        "    valid_scores = []\r\n",
        "    train_scores = []\r\n",
        "\r\n",
        "    # Iterate through each fold\r\n",
        "    for train_indices, valid_indices in k_fold.split(features):\r\n",
        "        \r\n",
        "        # Training data for the fold\r\n",
        "        train_features, train_labels = features[train_indices], labels[train_indices]\r\n",
        "        # Validation data for the fold\r\n",
        "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\r\n",
        "\r\n",
        "        # Create the model\r\n",
        "        model = TabNetClassifier(\r\n",
        "                    n_d=32, \r\n",
        "                    n_a=32, \r\n",
        "                    n_steps=10,\r\n",
        "                    gamma=0.098, \r\n",
        "                    n_independent=2, \r\n",
        "                    n_shared=2,\r\n",
        "                    lambda_sparse=1e-3, \r\n",
        "                    momentum=0.4, \r\n",
        "                    clip_value=2.,\r\n",
        "                    optimizer_fn=torch.optim.Adam,\r\n",
        "                    scheduler_params = {\"gamma\": 0.95,\r\n",
        "                                    \"step_size\": 20},\r\n",
        "                    optimizer_params=dict(lr=2e-2),\r\n",
        "                    scheduler_fn=torch.optim.lr_scheduler.StepLR, \r\n",
        "                    epsilon=1e-15, verbose = 0,\r\n",
        "                    device_name='cuda'\r\n",
        "                )\r\n",
        "        \r\n",
        "        # Train the model\r\n",
        "        model.fit(\r\n",
        "            train_features, train_labels[:,0],\r\n",
        "            eval_set=[(train_features, train_labels[:,0]), (valid_features, valid_labels[:,0])],  \r\n",
        "            eval_name=['train', 'valid'],\r\n",
        "            eval_metric=['auc'],\r\n",
        "            max_epochs=1000 , patience=50,\r\n",
        "            batch_size=1024, virtual_batch_size=128,\r\n",
        "            num_workers=0,\r\n",
        "            weights=1,\r\n",
        "            drop_last=False\r\n",
        "        )\r\n",
        "\r\n",
        "        print(model)\r\n",
        "        \r\n",
        "        # Make predictions\r\n",
        "        test_predictions += model.predict_proba(test_features)[:, 1] / k_fold.n_splits\r\n",
        "        \r\n",
        "        # Record the out of fold predictions\r\n",
        "        out_of_fold[valid_indices] = model.predict_proba(valid_features)[:, 1]\r\n",
        "\r\n",
        "        # Record the best score\r\n",
        "        valid_score = roc_auc_score(valid_labels, model.predict(valid_features))\r\n",
        "        train_score = roc_auc_score(train_labels, model.predict(train_features))\r\n",
        "        \r\n",
        "        valid_scores.append(valid_score)\r\n",
        "        train_scores.append(train_score)\r\n",
        "        \r\n",
        "        # Clean up memory\r\n",
        "        gc.enable()\r\n",
        "        del model, train_features, valid_features\r\n",
        "        gc.collect()\r\n",
        "        \r\n",
        "    # Make the submission dataframe\r\n",
        "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\r\n",
        "    \r\n",
        "    # Overall validation score\r\n",
        "    valid_auc = roc_auc_score(labels, out_of_fold)\r\n",
        "    \r\n",
        "    # Add the overall scores to the metrics\r\n",
        "    valid_scores.append(valid_auc)\r\n",
        "    train_scores.append(np.mean(train_scores))\r\n",
        "    \r\n",
        "    # Needed for creating dataframe of validation scores\r\n",
        "    fold_names = list(range(n_folds))\r\n",
        "    fold_names.append('overall')\r\n",
        "    \r\n",
        "    # Dataframe of validation scores\r\n",
        "    metrics = pd.DataFrame({'fold': fold_names,\r\n",
        "                            'train': train_scores,\r\n",
        "                            'valid': valid_scores}) \r\n",
        "    \r\n",
        "    return submission, metrics"
      ],
      "outputs": [],
      "metadata": {
        "id": "P4YtogqvQvk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "submission, metrics = model(train, test, labels, test_ids)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcFM1uTxRzUo",
        "outputId": "f6d86175-dbcd-4c39-a0f4-27803b3daa1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('TabNet metrics')\r\n",
        "print(metrics)"
      ],
      "outputs": [],
      "metadata": {
        "id": "KAjIfITZR1GC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scaler = MinMaxScaler()\r\n",
        "tn = submission['TARGET'].to_numpy().reshape(-1, 1)\r\n",
        "scaler.fit(tn)\r\n",
        "tg = scaler.transform(tn)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': tg[:,0]})"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "submission.to_csv('tabnet.csv', index = False)"
      ],
      "outputs": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-15T08:41:59.771442Z",
          "iopub.status.idle": "2021-08-15T08:41:59.771958Z"
        },
        "trusted": true,
        "id": "hxy2sCpJOPdZ"
      }
    }
  ]
}