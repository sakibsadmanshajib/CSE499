@online{dataset,
  author = "Home Credit Group",
  year = "2018",
  title = "Home Credit Default Risk",
  url = "https://www.kaggle.com/c/home-credit-default-risk/data",
  lastaccessed = "February, 2021",
  organization = "Kaggle",
}

@InProceedings{deepgbm,
author = {Ke, Guolin and Xu, Zhenhui and Zhang, Jia and Bian, Jiang and Liu, Tie-Yan},
title = {DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks},
booktitle = {KDD '19 Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
year = {2019},
month = {August},
abstract = {Online prediction has become one of the most essential tasks in many real-world applications. Two main characteristics of typical online prediction tasks include tabular input space and online data generation. Specifically, tabular input space indicates the existence of both sparse categorical features and dense numerical ones, while online data generation implies continuous task-generated data with potentially dynamic distribution. Consequently, effective learning with tabular input space as well as fast adaption to online data generation become two vital challenges for obtaining the online prediction model. Although Gradient Boosting Decision Tree (GBDT) and Neural Network (NN) have been widely used in practice, either of them yields their own weaknesses. Particularly, GBDT can hardly be adapted to dynamic online data generation, and it tends to be ineffective when facing sparse categorical features; NN, on the other hand, is quite difficult to achieve satisfactory performance when facing dense numerical features. In this paper, we propose a new learning framework, DeepGBM, which integrates the advantages of the both NN and GBDT by using two corresponding NN components: (1) CatNN, focusing on handling sparse categorical features. (2) GBDT2NN, focusing on dense numerical features with distilled knowledge from GBDT. Powered by these two components, DeepGBM can leverage both categorical and numerical features while retaining the ability of efficient online update. Comprehensive experiments on a variety of publicly available datasets have demonstrated that DeepGBM can outperform other well-recognized baselines in various online prediction tasks.},
url = {https://www.microsoft.com/en-us/research/publication/deepgbm-a-deep-learning-framework-distilled-by-gbdt-for-online-prediction-tasks/},
}

@INPROCEEDINGS{9107890,  author={Qiu, Ziyue and Li, Yuming and Ni, Pin and Li, Gangmin},  booktitle={2019 6th International Conference on Information Science and Control Engineering (ICISCE)},   title={Credit Risk Scoring Analysis Based on Machine Learning Models},   year={2019},  volume={},  number={},  pages={220-224},  doi={10.1109/ICISCE48695.2019.00052}}

@misc{gomes_2021, title={GitHub - MAGomes95/KaggleCreditRisk}, url={https://github.com/MAGomes95/KaggleCreditRisk}, journal={GitHub}, author={Gomes, Mario}, year={2021} },



@misc{yasumizu_2021, title={Fork of Magic Of Weighted Average Rank [0.80]}, url={https://www.kaggle.com/yyoshiaki/fork-of-magic-of-weighted-average-rank-0-80}, journal={Kaggle.com}, author={Yasumizu, Yoshiaki}, year={2021} }

@inproceedings{Liang2019LoanlinessPL,
  title={Loanliness: Predicting Loan Repayment Ability by Using Machine Learning Methods},
  author={Y. Liang},
  year={2019}
}

@article{Chen_2016,
   title={XGBoost},
   ISBN={9781450342322},
   url={http://dx.doi.org/10.1145/2939672.2939785},
   DOI={10.1145/2939672.2939785},
   journal={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
   publisher={ACM},
   author={Chen, Tianqi and Guestrin, Carlos},
   year={2016},
   month={Aug}
}

@inproceedings{Ke2017LightGBMAH,
  title={LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
  author={Guolin Ke and Qi Meng and Thomas Finley and Taifeng Wang and Wei Chen and Weidong Ma and Q. Ye and Tie-Yan Liu},
  booktitle={NIPS},
  year={2017}
}

@misc{sklearn.ensemble.randomforestclassifier, url={https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}, journal={Scikit-learn.org}, year={2021} }, 

@misc{sklearn.linear_model.logisticregression, url={https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html}, journal={Scikit-learn.org}, year={2021} }

@misc{arik2020tabnet,
      title={TabNet: Attentive Interpretable Tabular Learning}, 
      author={Sercan O. Arik and Tomas Pfister},
      year={2020},
      eprint={1908.07442},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{10.1145/3366194.3366333,
author = {Chen, Xue and Liu, Zhenlong and Zhong, Ming and Liu, Xin and Song, Peng},
title = {A Deep Learning Approach Using DeepGBM for Credit Assessment},
year = {2019},
isbn = {9781450372985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366194.3366333},
doi = {10.1145/3366194.3366333},
abstract = {In the loan business, the bank needs to conduct credit assessment on customers to
reduce the loan risk. How to assess personal credit has become a problem which is
worth studying. In the traditional credit assessment methods, logistic regression,
decision tree, random forest, and other methods were often used to conduct credit
assessment for individuals. In recent years, a new machine learning method, LightGBM
[1] has also been used in credit assessment and achieved good results. In the models
mentioned above, the problem of sparse categorical features and dense numerical features
of the credit assessment data set is not solved yet. DeepGBM[2] proposed by Guolin
Ke, Zhenhui Xu* and Jia Zhang can solve the problem of credit assessment data set
very well. Therefore, our research adopted the latest deep learning framework DeepGBM.
The deep learning framework of DeepGBM consists of two parts, CatNN, and GBDT2NN,
which are used to deal with sparse categorical features and dense numerical features,
respectively. This paper used a data set from Kaggle: Home Credit Default Risk. We
had conducted several different experimental methods on this data set. The final results
of these experiments demonstrate that the performance of DeepGBM is better than other
models.},
booktitle = {Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {774–779},
numpages = {6},
keywords = {DeepGBM, Credit assessment, GBDT, Machine learning},
location = {Shanghai, China},
series = {RICAI 2019}
}

@misc{neural_network_2021, url={https://www.kaggle.com/ymatioun/basic-features-from-app-simple-neural-network}, journal={Kaggle.com}, year={2021} }

@inproceedings{NIPS2017_6449f44a,
 author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
 url = {https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {30},
 year = {2017}
}


@misc{shwartzziv2021tabular,
      title={Tabular Data: Deep Learning is Not All You Need}, 
      author={Ravid Shwartz-Ziv and Amitai Armon},
      year={2021},
      eprint={2106.03253},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{pyrohov_2020, title={Usage of stratified sampling of control subset for predicativity improvement of boosted decision tree models}, DOI={10.33111/mise.99.10}, number={99}, journal={Modeling and Information Systems in Economics}, author={Pyrohov, Viacheslav}, year={2020}, pages={119-131} }

@misc{parameters_lightgbm, url={https://lightgbm.readthedocs.io/en/latest/Parameters.html}, journal={Lightgbm.readthedocs.io}, year={2021} }, 
@misc{parameters_tuning_lightgbm, url={https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html}, journal={Lightgbm.readthedocs.io}, year={2021} }

@misc{sklearn.model_selection.gridsearchcv, url={https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html}, journal={Scikit-learn.org}, year={2021} }

@article{liu_zhang_2021, title={Credit evaluation with a data mining approach based on gradient boosting decision tree}, volume={1848}, DOI={10.1088/1742-6596/1848/1/012034}, number={1}, journal={Journal of Physics: Conference Series}, author={Liu, Zhenlong and Zhang, Yuheng}, year={2021}, pages={012034} }

@project{Osei_2021,
author = {Osei, Salomey and SADEFO KAMDEM, Jules and Nyunga, Berthine and Fadugba, Jeremiah},
year = {2021},
month = {03},
pages = {},
title = {Accuracies of some Learning or Scoring Models for Credit Risk Measurement},
doi = {10.13140/RG.2.2.22472.44803}
}

@misc{sklearn.preprocessing.onehotencoder, url={https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html}, journal={Scikit-learn.org}, year={2021} }, 
@misc{pandas.factorize, url={https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.factorize.html}, journal={Pandas.pydata.org}, year={2021} }

@misc{sklearn.impute.simpleimputer, url={https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html}, journal={Scikit-learn.org}, year={2021} }, 
@misc{sklearn.preprocessing.minmaxscaler, url={https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html}, journal={Scikit-learn.org}, year={2021} }

@article{10.1001/jama.2016.7653,
    author = {Tolles, Juliana and Meurer, William J.},
    title = "{Logistic Regression: Relating Patient Characteristics to Outcomes}",
    journal = {JAMA},
    volume = {316},
    number = {5},
    pages = {533-534},
    year = {2016},
    month = {08},
    abstract = "{In a recent issue of JAMA, Seymour et al presented a new method for estimating the probability of a patient dying of sepsis using information on the patient’s respiratory rate, systolic blood pressure, and altered mentation. The method used these clinical characteristics—called “predictor” or explanatory or independent variables—to estimate the likelihood of a patient having an outcome of interest, called the dependent variable. To determine the best way to use these clinical characteristics, the authors used logistic regression, a common statistical method for quantifying the relationship between patient characteristics and clinical outcomes.}",
    issn = {0098-7484},
    doi = {10.1001/jama.2016.7653},
    url = {https://doi.org/10.1001/jama.2016.7653},
    eprint = {https://jamanetwork.com/journals/jama/articlepdf/2540383/jgm160003.pdf},
}

@article{narkhede2018understanding,
  title={Understanding auc-roc curve},
  author={Narkhede, Sarang},
  journal={Towards Data Science},
  volume={26},
  pages={220--227},
  year={2018}
}

@article{friedman2001greedy,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@misc{xgboost_2021, url={https://towardsdatascience.com/boosting-algorithm-xgboost-4d9ec0207d}, journal={Towards Data Science}, year={2021} }

@misc{gbm_2021, url={https://towardsdatascience.com/boosting-algorithm-gbm-97737c63daa3}, journal={Towards Data Science}, year={2021} }

@misc{xgboost_parameters_2021, url={https://xgboost.readthedocs.io/en/latest/parameter.html}, journal={Xgboost.readthedocs.io}, year={2021} }, 
@misc{xgboost_tree_methods_2021, url={https://xgboost.readthedocs.io/en/latest/treemethod.html}, journal={Xgboost.readthedocs.io}, year={2021} }

@misc{xgboost_gpu_support_2021, url={https://xgboost.readthedocs.io/en/latest/gpu/index.html}, journal={Xgboost.readthedocs.io}, year={2021} }

@misc{home_credit_default_risk_approaching_with_nn, url={https://www.kaggle.com/ilmiatfarhana/home-credit-default-risk-approaching-with-nn}, journal={Kaggle.com}, year={2021} }

@misc{Start_Here_:_A_Gentle_Introduction, url={https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction}, journal={Kaggle.com}, year={2021} }

@misc{random_forest_2021, url={https://www.tibco.com/reference-center/what-is-a-random-forest}, journal={TIBCO Software}, year={2021} }